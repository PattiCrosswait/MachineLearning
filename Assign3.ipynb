{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1) Load the dataset and split it into a training set (70%) and a test set (30%). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer \n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "#Splitting the data into Training Set and Test Set \n",
    "from sklearn.model_selection import train_test_split \n",
    "X_trainOrig, X_testOrig, y_trainOrig, y_testOrig = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "\n",
    "#Normalizing the features \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "sc_X = StandardScaler() \n",
    "X_trainOrig = sc_X.fit_transform(X_trainOrig) \n",
    "X_testOrig = sc_X.transform(X_testOrig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2) Train Logistic Regression on the dataset and time how long it takes. Look up how to compute execution time of Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.9687018394470215 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#Fitting Logistic Regression to Training Set \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "classifierObj = LogisticRegression(random_state=0) \n",
    "classifierObj.fit(X_trainOrig, y_trainOrig)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3) Evaluate the resulting model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 60,   3],\n",
       "       [  1, 107]], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making predictions on the Test Set \n",
    "y_predOrig = classifierObj.predict(X_testOrig)\n",
    "\n",
    "#Evaluating the predictions using a Confusion Matrix \n",
    "from sklearn.metrics import confusion_matrix \n",
    "cm = confusion_matrix(y_testOrig, y_predOrig)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4) Next, use PCA to reduce the dataset’s dimensionality, with an explained variance ratio of at least 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.36893153e-01, 1.94151626e-01, 9.66154484e-02, 6.71661075e-02,\n",
       "       5.49883033e-02, 4.01225718e-02, 2.18306816e-02, 1.48922601e-02,\n",
       "       1.37410827e-02, 1.10137130e-02, 1.04826288e-02, 9.16214247e-03,\n",
       "       7.66306051e-03, 5.14226331e-03, 3.19635178e-03, 2.51968451e-03,\n",
       "       1.92415148e-03, 1.65844223e-03, 1.49026749e-03, 1.06777316e-03,\n",
       "       1.01725216e-03, 8.48954816e-04, 7.43492725e-04, 5.81295611e-04,\n",
       "       5.44222785e-04, 2.53545469e-04, 2.14385701e-04, 4.62967124e-05,\n",
       "       2.51158320e-05, 3.72534805e-06])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying PCA \n",
    "from sklearn.decomposition import PCA \n",
    "pcaObj = PCA(n_components=None)\n",
    "X_trainPCA = pcaObj.fit_transform(X_trainOrig) \n",
    "X_testPCA = pcaObj.transform(X_testOrig) \n",
    "components_variance = pcaObj.explained_variance_ratio_\n",
    "components_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5) Train a new Logistic Regression classifier on the PCA reduced dataset and see how long it takes. Was training much faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.015573501586914062 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#Fitting Logistic Regression to Training Set \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "classifierObj = LogisticRegression(random_state=0) \n",
    "classifierObj.fit(X_trainPCA, y_trainOrig)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "#Making predictions on the Test Set \n",
    "y_predPCA = classifierObj.predict(X_testPCA)\n",
    "#MUCH FASTER 0.01557 secs vs. 0.9687 secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6) Next evaluate the classifier on the test set: how does it compare to the previous classifier? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 60,   3],\n",
       "       [  1, 107]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating the predictions using a Confusion Matrix \n",
    "from sklearn.metrics import confusion_matrix \n",
    "cm = confusion_matrix(y_testOrig, y_predPCA)\n",
    "cm\n",
    "\n",
    "#previous classifier confusion matrix  \n",
    "#array([[ 60,   3],\n",
    "#       [  1, 107]], dtype=int64)\n",
    "\n",
    "#This classifier\n",
    "#array([[ 60,   3],\n",
    "#       [  1, 107]], dtype=int64)\n",
    "#The confusion matrix is the same from the previous classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7) Use LDA to reduce the dataset’s dimensionality down to 2 linear discriminants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying LDA \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA \n",
    "ldaObj = LDA(n_components=2) \n",
    "X_trainLDA = ldaObj.fit_transform(X_trainOrig,y_trainOrig)\n",
    "X_testLDA = ldaObj.transform(X_testOrig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8) Train a new Logistic Regression classifier on the LDA reduced dataset and see how long it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.0 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#Fitting Logistic Regression to Training Set \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "classifierObj = LogisticRegression(random_state=0) \n",
    "classifierObj.fit(X_trainLDA, y_trainOrig)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "#Making predictions on the Test Set \n",
    "y_predLDA = classifierObj.predict(X_testLDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9) Evaluate the classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59,   4],\n",
       "       [  2, 106]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating the predictions using a Confusion Matrix \n",
    "from sklearn.metrics import confusion_matrix \n",
    "cm = confusion_matrix(y_testOrig, y_predLDA)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10) Use Kernel PCA to reduce the dataset’s dimensionality down to 2 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel PCA \n",
    "from sklearn.decomposition import KernelPCA \n",
    "kernelPCAObj = KernelPCA(n_components=2, kernel='rbf') \n",
    "X_trainKernalPCA = kernelPCAObj.fit_transform(X_trainOrig) \n",
    "X_testKernalPCA = kernelPCAObj.transform(X_testOrig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11) Train a new Logistic Regression classifier on the Kernel PCA reduced dataset and see how long it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.0 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#Fitting Logistic Regression to Training Set \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "classifierObj = LogisticRegression(random_state=0) \n",
    "classifierObj.fit(X_trainKernalPCA, y_trainOrig)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "#Making predictions on the Test Set \n",
    "y_predKernalPCA = classifierObj.predict(X_testKernalPCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q12) Evaluate the classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56,  7],\n",
       "       [10, 98]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating the predictions using a Confusion Matrix \n",
    "from sklearn.metrics import confusion_matrix \n",
    "cm = confusion_matrix(y_testOrig, y_predKernalPCA)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
